\documentclass[a4paper, 12pt]{extarticle}
\usepackage[utf8]{inputenc}

\usepackage{cite}
\usepackage{float}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{parskip}


% >= 3.45cm is too large to fit 2 names per row
\usepackage[left=3cm,right=3cm]{geometry}


\title{
    CITS4404 Team Project - Building AI Trading Bots
    \\ \large Group 6 - Literature Review
}
\author{
    Chen, Zijian\\
    \normalsize \texttt{22998691@student.uwa.edu.au}
    \and
    Dai, Ethan\\
    \normalsize \texttt{23625929@student.uwa.edu.au}
    \and
    Ida Bagus Prawira Janottama Kn\\
    \normalsize \texttt{23894575@student.uwa.edu.au}
    \and
    Nadeesha Adikari Adikari Appuhamilage\\
    \normalsize \texttt{24041382@student.uwa.edu.au}
    \and
    Su, Daniel\\
    \normalsize \texttt{22965999@student.uwa.edu.au}
    \and
    Townshend, Nathan\\
    \normalsize \texttt{22970882@student.uwa.edu.au}
}
\date{\today}

\begin{document}

\clearpage

\maketitle


\newpage
\tableofcontents


\newpage
\section{Introduction}\label{sec:intro}
% \input{introduction}


\newpage
\section{Gravity Search Algorithm}\label{sec:alg:gsa}
\input{gsa}

% Ethan's section
\newpage
\section{Modified Particle Swarm Optimisation with Simulated Annealing}

\subsection{Particle Swarm Optimisation}

Particle Swarm Optimisation (PSO) was first introduced by Kennedy and Eberhart \cite{kennedy1995particle} in 1995 as a method for optimisation in continuous nonlinear hypothesis spaces. It was inspired by the swarming social behaviour exhibited naturally by species such as fish or birds. The motivation for mimicking nature in this particular way was the observation that individual members in flocks benefit from the collective experiences of all other members \cite{wilson2000sociobiology}. An example could be birds flocking to a food source, many individuals within the flock would have no prior knowledge of the location of a new food source but the information spreads to all individuals through flocking behaviour. 

The original PSO algorithm operated on several basic rules for each individual within the swarm. Using some cost function, each individual remembered its own personal best (pbest) position and also knows the global best (gbest) position found by any individual within the swarm.

The velocity update of an individual depends on its distance relative to both pbest and gbest with hyperparameters p\_increment and g\_increment determining the magnitude of the velocity increase towards either point. The resulting velocity update is a vector addition of the velocity towards pbest and gbest.


\subsection{Motivating Particle Swarm Optimisation with Simulated Annealing}

Particle Swarm Optimisation with Simulated Annealing (SA-PSO) was introduced by Shieh et al. \cite{shieh2011modified} to address two optimisation issues at the time of publishing.

\begin{enumerate}
    \item Genetic Algorithms (GA) struggled with epistasis where genes were highly correlated with each other within the chromosome causing issues with crossover for new generations. It was also more computationally inefficient compared to PSO.
    \item PSO struggled with premature convergence to local minima due to localisation of the particles. Due to the attraction to pbest and gbest, exploration is largely discouraged in the algorithm.
\end{enumerate}

Simulated Annealing (SA) provides an exploration property using the metropolis process, which converges asymptomatically to the global optimum given certain preconditions. 
A novel SA and PSO hybrid approach is proposed due to the computational efficiency of PSO compared to other optimisation algorithms and the more stable convergence properties of SA stemming from the algorithm’s greater ability to explore the hypothesis space. 

\subsection{Method and Results}

The SA-PSO algorithm contains 6 hyperparameters that require tuning before being applied to the benchmark functions. This is performed through a coarse exhaustive search of all potential values within a range. For example, the initial temperature value was tested for between 50 and 90 in increments of 10.

The proposed SA-PSO algorithm and baseline GA, SA and PSO algorithms are then benchmarked on a selection of test functions with various dimensionality mostly taken from mathematics and physics such as the Zakharov function. The indicator used for performance is the rate of obtaining the optimal solution.

Each algorithm was run on each benchmark function 100 times. The final performance metric comparing SA-PSO to its predecessor algorithms is the average rate of obtaining the optimal solution.

The new algorithm demonstrated a significant performance improvement over the second-best algorithm PSO at an average convergence rate of 98.7\% compared to 92.5\%.

The consistency of the algorithms were also demonstrated through the mean value of the solution obtained over the 100 runs for each benchmark function. SA-PSO demonstrated means which were closest to the known optimum on the vast majority of benchmarks demonstrating the stability of convergence of the algorithm.

\subsection{Discussion}

The paper concluded that SA-PSO demonstrated strong results as a consequence of combining the explorative nature of SA to counteract the tendency of PSO to fall into local extrema. The performance justifies the claim that that SA-PSO is a capable optimisation algorithm for non-linear optimisation problems. 
However, the benchmark functions were all continuous and well-defined functions. The performance of SA-PSO on real-world data cannot be extrapolated from this paper as it may not be differentiable or continuous.

% Nadeesha's section
\newpage
\section{Grey Wolf Optimizer}
The Grey Wolf Optimizer (GWO) aims to overcome key limitations in existing optimization algorithms, such as getting trapped in local optima, poor convergence behaviour, and an imbalance between exploration and exploitation. While algorithms like Particle Swarm Optimization (PSO), Gravitational Search Algorithm (GSA), and Differential Evolution (DE) have been successful in many scenarios, they often struggle with these issues. GWO addresses them by mimicking the social hierarchy and hunting strategies of grey wolves, leading to a more adaptive and balanced search process. The algorithm's structure, based on four types of wolves: alpha ($\alpha$), beta ($\beta$), delta ($\delta$), and omega ($\omega$), enhances its ability to explore the search space globally and exploit promising regions effectively\cite{mirjalili2014grey}.

The paper \cite{mirjalili2014grey} highlights that metaheuristic techniques tend to outperform classical heuristics due to their simplicity, ability to avoid local optima, flexibility across different problem domains without structural changes, and their derivative-free approach that enables the process to begin from a random solution. Moreover, population-based algorithms have shown significant advantages over single-solution-based approaches.

GWO is a metaheuristic, population-based, swarm intelligence algorithm inspired by the social hierarchy and hunting behaviour of grey wolves. However, many existing algorithms still face critical challenges. A major issue is local optima trapping, where the algorithm prematurely settles on suboptimal solutions. Another significant challenge is the lack of balance between exploration and exploitation, some algorithms overexploit early good solutions and fail to adequately explore the broader search space, especially due to their stochastic behaviour. Furthermore, slow or improper convergence is also a limitation, as some algorithms struggle to efficiently reach high-quality solutions due to weak search strategies.These limitations have motivated the development of the GWO, which seeks to address these deficiencies through a more effective and biologically inspired approach. 

Although many earlier swarm intelligence (SI) algorithms were inspired by natural hunting or search behaviors, they often overlooked the internal leadership dynamics within animal groups. The Grey Wolf Optimizer (GWO) introduces a novel idea by simulating the leadership hierarchy and social behaviour of grey wolves. It categorizes the population into four types of wolves, alpha ($\alpha$), beta ($\beta$), delta ($\delta$), and omega ($\omega$), to represent the hierarchy of decision-making. The alpha wolf represents the current best solution, the beta and delta are the second and third best, while the remaining candidates are considered omega wolves.

The algorithm also mimics the three main phases of hunting: searching for prey, encircling prey, and attacking prey. These behaviors guide the population’s movement in the search space, with the alpha, beta, and delta wolves influencing the search direction. This structured yet dynamic mechanism allows the GWO algorithm to maintain a high degree of randomness and diversity, helping it to avoid local optima. \cite{kandasamy2020literature}

The new approach is demonstrated through benchmarking experiments on 29 test functions. Among these, 23 are classical benchmark functions, and the remaining 6 are composite benchmark functions. These functions are used to evaluate the algorithm’s performance in terms of exploration, exploitation, and local optima avoidance. Unimodal functions are used for exploitation analysis, multimodal functions for exploration analysis, and composite benchmark functions for local minima avoidance analysis. The algorithm was run 300 times for each benchmark, and statistical results (average and standard deviation) were compared to other popular swarm intelligence algorithms.   Additionally, the GWO algorithm is applied to three classical engineering design problems: tension design, welded beam design, and pressure vessel design. It was also tested on a real-world optical buffer design problem, running the algorithm 20 times to validate its ability to solve real-world problems with constraints. \cite{mirjalili2016multi}.

The performance of GWO was validated through benchmarking against well-known optimization algorithms, such as PSO, GSA, and GA, across various test functions, including unimodal, multimodal, and composite functions. Statistically significant improvements were observed in key metrics such as Delay-Bandwidth Product (DBP) and Normalized DBP (NDBP), with GWO achieving a 93\% improvement in bandwidth and a 65\% improvement in NDBP compared to existing methods. Additionally, the algorithm was applied to a real-world optical buffer design problem, where it demonstrated superior performance.The results were validated through multiple runs to ensure consistency, and the algorithm was tested on a high-performance computing (HPC) cluster using multiple CPUs, validating its robustness in solving large-scale, complex problems.

The conclusions presented in the paper are generally well-supported by the experimental results. The authors demonstrate that GWO performs competitively against established optimization algorithms across a wide range of benchmark functions and real-world problems. The balance between exploration and exploitation is effectively illustrated, and the algorithm shows strong potential in avoiding local optima and achieving reliable convergence. However, while the findings are promising, broader testing on diverse problem domains would help further validate the general applicability of the approach. 

\newpage
\section{Conclusions}\label{sec:conc}
% \input{conclusion}
% alg comparrison?


\newpage
\phantomsection
\section{References}
\vspace{-24pt}
\renewcommand{\refname}{}
\bibliographystyle{IEEEtran}
\bibliography{main,gsa}

\end{document}
