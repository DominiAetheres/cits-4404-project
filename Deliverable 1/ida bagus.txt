Summary: Harris Hawks Optimisation (HHO)

The paper presents a new algorithm called Harris Hawks Optimiser, known as HHO [1]. It aims to solve difficult optimisation problems. Many real-world problems are complex, they might involve many variables, have many possible good solutions which is called multimodal behaviour, change suddenly meaning they are non-differentiable, or have strict rules also known as constraints. Old methods, like standard mathematical techniques, often find these problems hard to solve. Newer algorithms, called metaheuristics like Genetic Algorithms or Particle Swarm Optimisation, are easier to use because they don't need complex maths. However, these newer algorithms also have problems. They can be sensitive to their settings, a process called parameter tuning, and sometimes get stuck on a solution that is good but not the best, known as a local optima. Also, a rule called the "No Free Lunch" theorem suggests no single algorithm is perfect for all problems. This encourages scientists to create new optimisation algorithms. HHO is a new algorithm, inspired by nature, designed to be a good option for solving these complex problems [1].

Older algorithms often failed because they were not efficient for the complex problems found in the real world. Even the newer metaheuristic algorithms can fail. They might find a quite good solution quickly but then get stuck there, called premature convergence or local optima stagnation. This happens if they don't do the exploration (balance searching widely for different solutions) and searching deeply near good solutions, known as exploitation. Also, their success can depend a lot on choosing the right settings, which can be difficult. The idea that no single algorithm works best for everything also motivates looking for new approaches like HHO [1].

HHO is new because it copies the teamwork and hunting style of Harris' hawks, especially their "surprise pounce" attack. The algorithm uses maths to copy how these smart birds hunt together. New ideas in HHO include copying how hawks work together to attack based on what the prey does, called the Teamwork Model. It uses a changing "escaping energy" number, represented as E, for the prey, which helps the algorithm switch smoothly from searching widely, the exploration phase, to searching deeply, the exploitation phase, as it runs, called the Changing Strategy. It has four different plans for the exploitation phase, chosen based on the prey's energy E and its chance of escaping, represented as r, copying how hawks change tactics, called Different Attack Plans. In some attack plans, HHO uses a special random walk called Levy flight, or LF, to copy the tricky, sudden movements of prey and the quick dives of the hawks, helping to search better in a local area. Also, hawks in the algorithm only move to a new position if it is better than their current one, which helps make the solutions better over time (Choosing Better Moves). These ideas aim to help HHO balance searching widely and searching deeply, avoid getting stuck on bad solutions, and find the best overall solution [1].

The paper explains the HHO algorithm using mathematical formulas. It describes the exploration phase, which involves searching widely, and the four different exploitation phases, which involve searching deeply using different plans based on prey energy and escape chance. Each phase has its own maths equation telling the hawks how to move. The authors tested how well HHO works by trying it on many problems. They used 29 standard test problems often used to check optimisation algorithms. These included simple problems known as unimodal, problems with many good-but-not-best solutions known as multimodal, and very complex mixed problems called composition problems. They tested if HHO still works well when the problems become very large, having high dimensions up to 1000 variables. They also used HHO to solve six real engineering design problems that have strict rules or constraints. The paper includes a pseudocode for the algorithm, and the authors say the computer code is available online, making it easier for others to check or use it [1].

HHO was compared to 11 other popular optimisation algorithms. The comparison looked at the best, worst, average, and consistency, measured by standard deviation, of the results over 30 tries for each problem. They also looked at how the algorithm behaved while searching, known as qualitative results. They tested how well HHO handled problems of increasing size, which is called scalability testing. A statistical test, the Wilcoxon rank-sum test, was used to see if HHO's better results were truly significant. The results showed HHO performed much better or was very competitive compared to the other algorithms on most test problems, including the very large ones. It was good at finding the best solutions and didn't slow down as much as others when problems got bigger. HHO also found the best or very good solutions for the real engineering problems. The statistical tests confirmed that HHO's improvements were meaningful in many cases [1].

The authors conclude that HHO is a very good optimisation algorithm. They state it gives excellent or competitive results compared to many well-known algorithms on both standard test problems and real engineering problems. They believe its success comes from its special mix of search strategies copied from Harris' hawks, like the changing energy level, the different attack plans using Levy flights, and only choosing better moves. They tested HHO thoroughly on many different types of problems, compared it fairly to many other algorithms, and used statistics to check the results. The results consistently show HHO performing very well, handling large problems effectively, and finding good solutions for real-world tasks. The paper provides strong evidence that HHO is a useful new optimisation algorithm [1].


Reference:

[1] A. A. Heidari, S. Mirjalili, H. Faris, I. Aljarah, M. Mafarja, and H. Chen, "Harris hawks optimization: Algorithm and applications," Future Generation Computer Systems, vol. 97, pp. 849-872, Aug. 2019, doi: 10.1016/j.future.2019.02.028.
